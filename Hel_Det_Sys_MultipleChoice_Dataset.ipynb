{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZLqtTuzWKVOQ",
    "outputId": "8c80f324-5082-49c0-df8b-f3591d088fa6"
   },
   "outputs": [],
   "source": [
    "pip install transformers sentence-transformers torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NP0menBgK1f1",
    "outputId": "1a7312f4-6b43-4771-93df-bcebf20862c3"
   },
   "outputs": [],
   "source": [
    "pip install datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "JRZARtQnP2V-",
    "outputId": "07884c30-3d65-4db9-beaa-37a1d7d3fe82"
   },
   "outputs": [],
   "source": [
    "pip install --upgrade datasets fsspec\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qRDYeuWcLV_x"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"WANDB_DISABLED\"] = \"true\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 258,
     "referenced_widgets": [
      "e454de847f76457f83ff49d1ecf80a1f",
      "42510caa396c410391b307381d95aa40",
      "f26f13e7471443a3b1d3a3b1a6aba1f8",
      "c23893ea785042de80296b468df86fc8",
      "ab9aa266660a4a9699707f8412ab8031",
      "c627c3e966f343e091a9d5956bf2cf34",
      "4fc6f5ecbcbb4fdeabb6d199dcfd7015",
      "caa6de9a69854811ad487f2f84d6c142",
      "8a1330f05c2b4396bd72901e3705018c",
      "a8fa3ca52f6c4857a2cb82c749bb0108",
      "4f2ba067e5b3456b92c942005b7c9a3e",
      "b70cbc91b65b40fc8d3e55c3d8876f61",
      "7fa231c5fced471a9d485d3dd3f2a6d8",
      "ff803d95c15a4f9d9347f03696e8afd9",
      "e97980795c2a4cffb16f2555d51a6551",
      "9ebde9d485464eaeb8040cbc57999351",
      "eae99c1a6ee04195b0ddccc25334eebc",
      "de09e6a5bf0f485297f78225dc4c74b0",
      "4c964442c4c44c74b6c4ae71c78ccb1d",
      "ca92d966b92743939cc0772ca86a4ea1",
      "49256a5aedf04e5887846139c6f61d0f",
      "61f449adc55140b9bac4edab2d946c3e",
      "265908fd04a7448c9fa7ff1eeb52d6a1",
      "4c7037998e9f430fac19b030f7a063d6",
      "198b62be020348f4b585509f7229c613",
      "1e126d84fc3b4d78a4141df03241952f",
      "34d0fb5fefc24f9a901c02d718e47514",
      "5cbd2c210005459ab72937d7ffdd4cf7",
      "7107b2e5d5de41319cef47ccd70e6594",
      "a22842bc3bdf48cbb89ede6d11932856",
      "a12066a0e3864461a0cd6217a82f29ba",
      "3b71b124ff644ab688cfec80bc1ab4bb",
      "bc624347ba674c6c9ee4b5511d3e82a9"
     ]
    },
    "id": "w5ChEUjOLYti",
    "outputId": "8583342d-4f95-414f-ecc6-6a7e3274bc9a"
   },
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "# Load the dataset\n",
    "dataset = load_dataset(\"truthful_qa\", \"multiple_choice\")\n",
    "\n",
    "# Inspect the data\n",
    "print(dataset[\"validation\"][0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iJ94KjjqLclk",
    "outputId": "b9659514-2380-45f4-9fa1-8aba6db9eedf"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Convert dataset into a DataFrame\n",
    "data = []\n",
    "for item in dataset[\"validation\"]:\n",
    "    question = item[\"question\"]\n",
    "    for i, answer in enumerate(item[\"mc1_targets\"][\"choices\"]):\n",
    "        label = item[\"mc1_targets\"][\"labels\"][i]  # 1 = true, 0 = hallucinated\n",
    "        data.append({\"question\": question, \"answer\": answer, \"label\": label})\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Split into training and validation sets\n",
    "train_df, val_df = train_test_split(df, test_size=0.2, random_state=42)\n",
    "\n",
    "print(train_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 851,
     "referenced_widgets": [
      "3d3f1ccaf23f4669995803a94564f43f",
      "fb8477c6a30641b7828f7d0f6f66b470",
      "e1a6bcfa7589401c814f87e05b7aa276",
      "2791c2c99d2447b78f2174c2f93a8888",
      "69486272c545450d9b9d9da684fd9c3e",
      "fd6267d9d0714b108fc5458b1463cafa",
      "0745195d6b2d4249a49d9bf2697c9125",
      "f50ea246eae04a5499d4ab975c5d7b1a",
      "1aa3834c191545f89817322ed64730aa",
      "c2c9512c9fb5450b88a39c69ba31dfa1",
      "e2ff7b76a542492cbec1cd005d15063a",
      "b1fa2c862b214d1aaaca7138a2d6396c",
      "e35bd858d4b5495fb72a68f364c8cf50",
      "c8f0bafb499f4991848f75a56cdaa4d1",
      "5eb678131b014969abc6cbb1c3e17225",
      "a39339c5f100412392853ede32a7ee1a",
      "1ca31e8d6abd467d986879372ccb994c",
      "eb0321526b8842a9b9da5d588b6331e6",
      "30a2553f9aa847da9902064b32e26b45",
      "692ed7bd417d4c07b4083dea0b317753",
      "ea595783076c4722bad3daae7116039f",
      "54aa2845ab5346c593dc90ecfa01617f",
      "7a9f8a574ae841ce8b8780c5fb84c288",
      "ea3f0f3ec8a448c2b1dff40d3b6e0845",
      "efa6e943f68848728f8be9b9c7d588ae",
      "ae3ff0b1d25842f8b130dacd06655195",
      "b38ce125d6884c1b920b6c0d1de57466",
      "062e90148716416eb4d437780e20586a",
      "33712c4722e042b8b9d31f38f5957323",
      "004cb70268a44d8f95ee5b6a5d83c0ab",
      "36f351e3fd814b3c9bc36b0df03e50b6",
      "1993fcb993b94fffb5d254493cc8e632",
      "f48510c55c5d45acaca2ec895db8b3ea",
      "a317a8d53dcb4bbbae6b9e9c14765f3e",
      "42e7b21d3bb845f2805f710d8976870d",
      "62ac5c3f832f4dd1a051a27e1cd149ca",
      "f70c301316b147e38932d40fe1c62b04",
      "7b1902bf43704966864addead7d6753a",
      "08027810942f4a90af7985bf1561b77d",
      "31209dd487ea4036b6db4b846c0c507b",
      "6a9c734a824c4adbb162f962ae69d89a",
      "28d2c41851714d239df33ca552050060",
      "68bd097e78e74502b4891a6de375bf87",
      "7dbca2ae21c74a8ab0d282caa9ac9651",
      "333bb43da5c041fc93b2ecd88783250e",
      "1ca5400875874d719de2d58a3fdd45bc",
      "d55edab902174125b9fec621b954f39e",
      "d1dc28196e5b4f2d9dca82cb8a7f0aae",
      "6ba4b62a2e6d44c0aa94bef0f401bc81",
      "23d5c69482ba4d1c9dd8b942d4ba8b39",
      "72d101854ffb48309fe0451a1ea08317",
      "a90fcc35f48c48cdb3430e83bebbe226",
      "dbb118df16394d338ee39d793f0ab4f5",
      "f2abd8d4a7b641ffb0ac0a344482f61e",
      "e8b0246f95fd46589bd2994203a07932"
     ]
    },
    "id": "T4G3DzrJLePl",
    "outputId": "2e83c528-879d-45c9-926f-930a7f978d10"
   },
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer, Trainer, TrainingArguments\n",
    "import torch\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "\n",
    "# Load a tokenizer and model\n",
    "model_name = \"distilbert-base-uncased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=2)\n",
    "\n",
    "# Tokenize data\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples[\"question\"], examples[\"answer\"], padding=\"max_length\", truncation=True)\n",
    "\n",
    "train_encodings = tokenize_function(train_df.to_dict(\"list\"))\n",
    "val_encodings = tokenize_function(val_df.to_dict(\"list\"))\n",
    "\n",
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions.argmax(-1)\n",
    "\n",
    "    # Compute accuracy, precision, recall, F1-score\n",
    "    accuracy = accuracy_score(labels, preds)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average=\"binary\")\n",
    "\n",
    "    return {\"accuracy\": accuracy, \"precision\": precision, \"recall\": recall, \"f1\": f1}\n",
    "\n",
    "\n",
    "# Convert to torch dataset\n",
    "class HallucinationDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item[\"labels\"] = torch.tensor(self.labels[idx])\n",
    "        return item\n",
    "\n",
    "train_dataset = HallucinationDataset(train_encodings, train_df[\"label\"].tolist())\n",
    "val_dataset = HallucinationDataset(val_encodings, val_df[\"label\"].tolist())\n",
    "\n",
    "# Training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    eval_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=15,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir=\"./logs\",\n",
    "    logging_steps=10,\n",
    ")\n",
    "\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "trainer.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 657
    },
    "id": "FwmNDqIkLh9s",
    "outputId": "ff741617-c0f8-41e5-d045-85ce465c1989"
   },
   "outputs": [],
   "source": [
    "\n",
    "from datasets import load_dataset\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments\n",
    "import torch\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "\n",
    "# Load the TruthfulQA dataset\n",
    "dataset = load_dataset(\"truthful_qa\", \"multiple_choice\")\n",
    "\n",
    "# Convert the dataset into a DataFrame\n",
    "data = []\n",
    "for item in dataset[\"validation\"]:\n",
    "    question = item[\"question\"]\n",
    "    for i, answer in enumerate(item[\"mc1_targets\"][\"choices\"]):\n",
    "        label = item[\"mc1_targets\"][\"labels\"][i]  # 1 = true, 0 = hallucinated\n",
    "        data.append({\"question\": question, \"answer\": answer, \"label\": label})\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Split into training and validation sets\n",
    "train_df, val_df = train_test_split(df, test_size=0.2, random_state=42)\n",
    "\n",
    "# Load a larger model, BERT\n",
    "model_name = \"bert-base-uncased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=2)\n",
    "\n",
    "# Tokenize the data\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples[\"question\"], examples[\"answer\"], padding=\"max_length\", truncation=True)\n",
    "\n",
    "train_encodings = tokenize_function(train_df.to_dict(\"list\"))\n",
    "val_encodings = tokenize_function(val_df.to_dict(\"list\"))\n",
    "\n",
    "# Convert the tokenized data into a Dataset class\n",
    "class HallucinationDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item[\"labels\"] = torch.tensor(self.labels[idx])\n",
    "        return item\n",
    "\n",
    "train_dataset = HallucinationDataset(train_encodings, train_df[\"label\"].tolist())\n",
    "val_dataset = HallucinationDataset(val_encodings, val_df[\"label\"].tolist())\n",
    "\n",
    "# Define a function to compute metrics\n",
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions.argmax(-1)\n",
    "    accuracy = accuracy_score(labels, preds)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average=\"binary\")\n",
    "    return {\"accuracy\": accuracy, \"precision\": precision, \"recall\": recall, \"f1\": f1}\n",
    "\n",
    "# Training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    eval_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=15,  # Increased epochs to 5 for better learning\n",
    "    weight_decay=0.01,\n",
    "    logging_dir=\"./logs\",\n",
    "    logging_steps=10,\n",
    ")\n",
    "\n",
    "# Initialize Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "trainer.train()\n",
    "\n",
    "# Evaluate the model\n",
    "eval_results = trainer.evaluate()\n",
    "print(eval_results)\n",
    "\n",
    "# Test function to classify a response\n",
    "def classify_response(question, answer):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "\n",
    "    inputs = tokenizer(question, answer, return_tensors=\"pt\", padding=\"max_length\", truncation=True)\n",
    "    inputs = {key: val.to(device) for key, val in inputs.items()}\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "\n",
    "    prediction = torch.argmax(outputs.logits).item()\n",
    "    return \"Truthful\" if prediction == 1 else \"Hallucinated\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 883,
     "referenced_widgets": [
      "8ec730ac33bd43beaaf71c18cffec277",
      "32bbe743bdab41f8937ee608fd889c08",
      "a967dd4e7ac84922b1e82064a09599c4",
      "1d2cb25c1427454ea43e8f87dc5bbc5c",
      "871c182d53c744fcb5fdad38afcf7abb",
      "5e81e8a61d7146f59d32983fbb13f752",
      "4a05c6b34d4740658bec635e5735b6fd",
      "32625b03e46d4887b3320f806f489ba1",
      "35c3fb96809c4255bec368b5cf2b3fd4",
      "cc6909947cc845e9886736c53bdc9429",
      "3248c658fb044d26be993ff82e71f33d",
      "56e14bc360334fa3a1bdfaf248c23db4",
      "72bf3819dbf846278023250fe5a22fa3",
      "516d1677b89d4fc4980751964b2c83d7",
      "73b7afdd799a488fb4381fa934c3073f",
      "2dc11e41e224416c9dc02d8d976d9f0a",
      "c64ef85abe8a4299b62b4e49085593d9",
      "d1704dc244154dd9be82618e7ced2203",
      "7b69cf05596a4762b086ad5db7341699",
      "08e10dc9fa674bfb859d6fe0c175d125",
      "c46405349d12421fbecc87b2646a5fcd",
      "f2e8be22881c4c21b7c68f5e715ae3fe",
      "16b9eb55285c4a81804a0e3e4e673134",
      "abd678457e1c4033a273afe34174ff9c",
      "f8ff9f1f9c4541bc9927d4dca6b80d55",
      "91d98e1206b847c589bdb954d43aae40",
      "c0a3678a6ec84c288ae959ce5f5f8764",
      "9a007f19a608414da857d145d5e8588d",
      "d4573eeafa6f4c9ea291eaedb0fe80f0",
      "9c56fda30d7d4a5da1bd802f8126f0dc",
      "495e325f18e741f385a1ab3f673b2098",
      "faff1e6d87064c828f4a2f02f692a6d9",
      "840833e34f61442bbd051f431685ceff",
      "9039fdbaa50b4acbaed3d5032a44e0a2",
      "97ee96c43cf7431f8e7d1a50afbf92f2",
      "51b4c79b055543b2a9d7d0bcdafcd5a4",
      "b6b7013da3114c60a46d78cba744bbbc",
      "bc29cedd1453430a9787a15e5b9d57af",
      "5399b598d3234dae9118a79db33526c6",
      "1ef24256d8274d93b841f430e43fc1eb",
      "f8d61a919b0f4c13823396b29451dab3",
      "3b53d7d090f24decb9f9c82107bc460c",
      "4a7d61aed6c24c8d8c7e6cd523823e03",
      "a97b3e0f1cce46ddb8c43e830304b0cc",
      "bc8414b33ba84396bcd18917fb162f60",
      "46819f38b6f944cb9e9a752e88d412ab",
      "24551012f5d641b88c9319ce2b4936f4",
      "d82ed70349c24db28eea9853e1f5ee2d",
      "e8e4f2fdaee7403484415d7c3d0de8de",
      "f6a975846a1e49cfaa23fc12572123db",
      "3e0cf7caab514e89b0a834ec991610d3",
      "a7bd72a09a10488eb907d769b8c865c7",
      "64e48ec9036d4f6abf6df952da0d6eda",
      "a420f1faef5340189babd7488475c296",
      "09cbe79f31c3453c9aa6e968b8f5cb13",
      "78442c66a43645c6bf15b567914a6aa5",
      "19597177c6c74b6fb701983702cd975a",
      "c7a1805eeecd42af990440c627712fa5",
      "4aa95e5ae56c4fa7a65be96117a9892e",
      "1672b55b2f344e95b7c1bdebf3a0c622",
      "76c0d4bf01c04b4ca5d814da880c738f",
      "1228100e26524da693ad775e734d8328",
      "875bd81fde6946f1920198780ccdcd18",
      "4bb0524878b34badae78ec0a8218f71a",
      "90e71a6c4827444a95fc3edaf74098da",
      "877d3c04703e418da29cf20be36a2b59"
     ]
    },
    "id": "dE-45fnQLiJv",
    "outputId": "fd782f29-4e89-4ba2-abf5-3803fdc37476"
   },
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments\n",
    "import torch\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "\n",
    "# Load and prepare dataset\n",
    "dataset = load_dataset(\"truthful_qa\", \"multiple_choice\")\n",
    "data = []\n",
    "for item in dataset[\"validation\"]:\n",
    "    question = item[\"question\"]\n",
    "    for i, answer in enumerate(item[\"mc1_targets\"][\"choices\"]):\n",
    "        label = item[\"mc1_targets\"][\"labels\"][i]\n",
    "        data.append({\"question\": question, \"answer\": answer, \"label\": label})\n",
    "df = pd.DataFrame(data)\n",
    "train_df, val_df = train_test_split(df, test_size=0.2, random_state=42)\n",
    "\n",
    "# Load tokenizer & model\n",
    "model_name = \"roberta-base\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=2)\n",
    "\n",
    "# Tokenization\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples[\"question\"], examples[\"answer\"], padding=\"max_length\", truncation=True, max_length=128)\n",
    "\n",
    "train_encodings = tokenize_function(train_df.to_dict(\"list\"))\n",
    "val_encodings = tokenize_function(val_df.to_dict(\"list\"))\n",
    "\n",
    "# Dataset class\n",
    "class HallucinationDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item[\"labels\"] = torch.tensor(self.labels[idx])\n",
    "        return item\n",
    "\n",
    "train_dataset = HallucinationDataset(train_encodings, train_df[\"label\"].tolist())\n",
    "val_dataset = HallucinationDataset(val_encodings, val_df[\"label\"].tolist())\n",
    "\n",
    "# Metrics\n",
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions.argmax(-1)\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average=\"binary\")\n",
    "    return {\"accuracy\": acc, \"precision\": precision, \"recall\": recall, \"f1\": f1}\n",
    "\n",
    "# Training config\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./roberta_results\",\n",
    "    eval_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=15,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir=\"./logs\",\n",
    "    logging_steps=10,\n",
    ")\n",
    "\n",
    "# Train\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "trainer.train()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "663c351fb754461c906afa0bd43f496e",
      "97f0d58e280c4a5282eb0b36e3013768",
      "b149529e9d0f4833bc3ee4c9d201f95f",
      "53500795398246538658f32d82eddc33",
      "2040362016304ff5827b2d9fc8715331",
      "c057615544f4487281ae45cb209a6b3b",
      "006362123a3642f29a362df863aaa445",
      "651eb4e84a42464fa4a90810854e4086",
      "47bbf9444e474871a634c1515a4b6977",
      "d0ab8560acf446b9990c946e80fb960c",
      "5ad4fe2eef954b53a7489ea061618f57",
      "c6b01a99a7a54dd4997b6eb7c181b747",
      "7dd835a1618a435487fa7458e6c3656d",
      "35aff876883b4cf28b71e7324f18b58b",
      "eaa22faefa1c4cd287af543a617b5049",
      "746dca49e0404ba38d77c9cfeedb8a87",
      "edd4b76b4c04473daa13d54cda94d697",
      "f82a215f07f04159b5d4e9b18775a451",
      "cd8e6949cdce452a98b6c4640fdd3a89",
      "7673aa9749e94e3f8e2b334a8cc8ae16",
      "4972b44085af4905858f1a27a93bea37",
      "8cff7364e4d5443f819c9276cea3f0ff",
      "53298935ad114cbeac0e48da1d5d9f1a",
      "539d36a4b7f84a45b783ae83583ec3fe",
      "f53937ca14b044cfb331f51cd027de03",
      "073c32fd8e594e848c18fa1fe753eacf",
      "af4fafa13d2147b3b8434a9ea8d6ae96",
      "314309e215c3492cad89b387a6811911",
      "dbb0d5231dc9419395a50d6ab1afe34d",
      "fa7b87d8bf554df88a429750e66bcbb5",
      "8272ce4ff7ae486d966771e559290f83",
      "056b1ca9445d4a87bff9bd71078c8680",
      "40c1cfbf59204e69b7f3602cf6412c17",
      "081bda5dccf448eda42e25563b62887e",
      "4dfd0b10cfa04c9b809841615b56f105",
      "eca54eef9f92488e8d92172b53c00519",
      "fa25569a9443410aa9281df98ec4834d",
      "5da73cdd4fc842309626effc9263473b",
      "e79581822df341c9ad497231d2e14cc8",
      "8ba653f5496e45ff95e8f94ffe2ce34b",
      "701884698c664a1b94edc711d862be4b",
      "108e6425f3734156be759050d6a502cc",
      "deab8ae8e9ad48f2bb70eec28bd0d313",
      "cc6e1e1895db43ed9fee5f12ca200d64",
      "92d89adec2964fca80844903436ea635",
      "ed82b78112ae4b74bff0e321b96109cb",
      "4012b7ee5c5c40128d992800e7acae95",
      "44ef223c4f7e439e9327a80ff181d9b4",
      "0ae566666cbe4c5494097081099e1d93",
      "689409d93bac4718bdb3512ae2469851",
      "34db1e38cf5240429a35f7c5a5fd6347",
      "17f3dd4f81d34aa2862044d90a7a46df",
      "41b769d46bbe4a868581cf308849120d",
      "0c3bafa268d2468fbb423a72e07d316c",
      "e043ff3ff08c4ca596600f0fcf2e54c0"
     ]
    },
    "id": "s3WOH0UTRw4S",
    "outputId": "d6fcdd53-9345-46cf-9482-5de83c11c3c5"
   },
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForSequenceClassification,\n",
    "    Trainer,\n",
    "    TrainingArguments,\n",
    "    DataCollatorWithPadding\n",
    ")\n",
    "\n",
    "# 1) Load & prepare the TruthfulQA dataset\n",
    "dataset = load_dataset(\"truthful_qa\", \"multiple_choice\")\n",
    "data = []\n",
    "for item in dataset[\"validation\"]:\n",
    "    q = item[\"question\"]\n",
    "    for i, ans in enumerate(item[\"mc1_targets\"][\"choices\"]):\n",
    "        lbl = item[\"mc1_targets\"][\"labels\"][i]  # 1=true, 0=hallucinated\n",
    "        data.append({\"question\": q, \"answer\": ans, \"label\": lbl})\n",
    "df = pd.DataFrame(data)\n",
    "train_df, val_df = train_test_split(df, test_size=0.2, random_state=42)\n",
    "\n",
    "# 2) Load DeBERTa‑v3\n",
    "model_name = \"microsoft/deberta-v3-base\"\n",
    "tokenizer  = AutoTokenizer.from_pretrained(model_name)\n",
    "model      = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=2)\n",
    "\n",
    "# 3) Tokenize with an explicit max_length\n",
    "def tokenize_function(exs):\n",
    "    return tokenizer(\n",
    "        exs[\"question\"],\n",
    "        exs[\"answer\"],\n",
    "        padding=\"max_length\",      # pad everything to...\n",
    "        truncation=True,           # ...and truncate longer ones\n",
    "        max_length=128             # <-- set your desired length\n",
    "    )\n",
    "\n",
    "train_encodings = tokenize_function(train_df.to_dict(\"list\"))\n",
    "val_encodings   = tokenize_function(val_df.to_dict(\"list\"))\n",
    "\n",
    "# 4) Wrap in a torch Dataset\n",
    "class HallucinationDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels    = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n",
    "        item[\"labels\"] = torch.tensor(self.labels[idx])\n",
    "        return item\n",
    "\n",
    "train_dataset = HallucinationDataset(train_encodings, train_df[\"label\"].tolist())\n",
    "val_dataset   = HallucinationDataset(val_encodings,   val_df[\"label\"].tolist())\n",
    "\n",
    "# 5) Data collator for dynamic padding (optional here since we used max_length)\n",
    "data_collator = DataCollatorWithPadding(tokenizer)\n",
    "\n",
    "# 6) Metrics function\n",
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds  = pred.predictions.argmax(-1)\n",
    "    acc    = accuracy_score(labels, preds)\n",
    "    p, r, f, _ = precision_recall_fscore_support(labels, preds, average=\"binary\")\n",
    "    return {\"accuracy\": acc, \"precision\": p, \"recall\": r, \"f1\": f}\n",
    "\n",
    "# 7) Training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./deberta_results\",\n",
    "    eval_strategy=\"epoch\",       # or evaluation_strategy=\"epoch\" in newer versions\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=20,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir=\"./logs\",\n",
    "    logging_steps=10,\n",
    ")\n",
    "\n",
    "# 8) Initialize Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    data_collator=data_collator,   # <-- ensures padding is consistent\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "# 9) Train & Evaluate\n",
    "trainer.train()\n",
    "eval_results = trainer.evaluate()\n",
    "print(eval_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Q5RQVfOBLiN4"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oSfMwZe7LiQ-"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
